{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7f2701-2f38-4eaa-8883-abd88c414138",
   "metadata": {},
   "source": [
    "#### Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f46b3-66f8-4e0a-bfc6-450480f6b186",
   "metadata": {},
   "source": [
    "Ans: Simple linear regression is a type of regression analysis where the relationship between two variables is modelled by a linear equation. It involves one dependent variable and one independent variable. An example of simple linear regression is predicting the salary of an employee based on their years of experience. Multiple linear regression is an extension of simple linear regression that involves more than one independent variable. An example of multiple linear regression is predicting the price of a house based on its size, number of rooms, and location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490b529-60ae-4318-b96a-3346c4a63362",
   "metadata": {},
   "source": [
    "#### Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5621395-af5c-4c4e-bbad-fa8e6c743a63",
   "metadata": {},
   "source": [
    "Ans: The assumptions of linear regression include linearity, homoscedasticity, independence of errors, normality of errors, and absence of multicollinearity. These assumptions can be checked by analyzing the residuals of the regression model, conducting hypothesis tests, and visual inspection of plots such as scatter plots and Q-Q plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a6691-732d-4130-900c-693d7e32a5fc",
   "metadata": {},
   "source": [
    "#### Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166468c4-76af-4a32-a47f-6514bd0f4459",
   "metadata": {},
   "source": [
    "Ans: The slope represents the change in the dependent variable for every one unit increase in the independent variable. The intercept represents the predicted value of the dependent variable when the independent variable is zero. For example, in a linear regression model predicting the weight of a person based on their height, the slope would represent the change in weight for every one unit increase in height, and the intercept would represent the predicted weight of a person who has zero height (which is not meaningful in practice)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb63f3f1-402e-4fcb-896b-a8d501118d41",
   "metadata": {},
   "source": [
    "#### Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e3b411-866a-487d-8892-3f35b6f1c9d9",
   "metadata": {},
   "source": [
    "Ans: Gradient descent is an optimization algorithm used to find the optimal parameters (slope and intercept) of a machine learning model by minimizing the error between the predicted and actual values. It involves iteratively adjusting the parameters in the direction of the steepest descent of the cost function until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850e4cc-8277-4481-9fae-c87965b7bd2f",
   "metadata": {},
   "source": [
    "#### Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df59dc60-3265-4a25-92b3-ba3c93da54af",
   "metadata": {},
   "source": [
    "Ans: Multiple linear regression is a type of regression analysis where the relationship between a dependent variable and two or more independent variables is modelled by a linear equation. It involves finding the best-fit line through the data points. The main difference from simple linear regression is the number of independent variables used to predict the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f53df40-06db-4ba5-bd5e-661ca7717e12",
   "metadata": {},
   "source": [
    "#### Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f90c4-ef46-4844-8bb0-500f9b834136",
   "metadata": {},
   "source": [
    "Ans: Multicollinearity in multiple linear regression occurs when two or more independent variables are highly correlated with each other. It can lead to unstable and unreliable parameter estimates, making it difficult to interpret the model. Multicollinearity can be detected using correlation matrices or variance inflation factor (VIF) analysis. To address this issue, one approach is to remove one of the correlated variables from the model, or combine them into a single variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd656b-2451-420f-83a2-19768bfd552e",
   "metadata": {},
   "source": [
    "#### Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143dafbf-0340-44da-a5f4-0fc279026f34",
   "metadata": {},
   "source": [
    "Ans: Polynomial regression is a type of regression analysis where the relationship between a dependent variable and one or more independent variables is modelled by a polynomial equation. It involves fitting a curve to the data points, instead of a straight line as in linear regression. Polynomial regression can capture non-linear relationships between variables that cannot be represented by a linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1997dc-b4ba-4c7d-a724-63951ee34d9e",
   "metadata": {},
   "source": [
    "#### Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7401e82b-8ea1-4afd-ba4a-d6584174d965",
   "metadata": {},
   "source": [
    "Ans: The advantages of polynomial regression include its ability to capture non-linear relationships between variables, flexibility in model fitting, and high accuracy for certain datasets. The disadvantages include overfitting, difficulty in interpretation of higher order terms, and increased complexity compared to linear regression. Polynomial regression is preferred when there is evidence of non-linear relationships between variables or when higher accuracy is desired."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
