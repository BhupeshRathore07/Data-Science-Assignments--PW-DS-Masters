{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7f2701-2f38-4eaa-8883-abd88c414138",
   "metadata": {},
   "source": [
    "#### Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cec141-587e-482f-9570-ddba4361991f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Ans: **R-squared (R²)** is a statistical measure that represents the proportion of variance in the dependent variable that is explained by the independent variables in a linear regression model. It is calculated as the ratio of the explained variance to the total variance of the dependent variable. R² takes values between 0 and 1, where a higher value indicates a better fit of the model to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490b529-60ae-4318-b96a-3346c4a63362",
   "metadata": {},
   "source": [
    "#### Q2. Define adjusted R-squared and explain how it differs from the regular R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db5b9f1-e1c6-4712-8ba4-c36138cbf692",
   "metadata": {},
   "source": [
    "Ans: **Adjusted R-squared** is a modified version of R-squared that takes into account the number of independent variables in the model. It adjusts R-squared by penalizing the addition of unnecessary independent variables. Adjusted R-squared is always lower than R-squared and is more appropriate to use when comparing models with different numbers of independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a6691-732d-4130-900c-693d7e32a5fc",
   "metadata": {},
   "source": [
    "#### Q3. When is it more appropriate to use adjusted R-squared?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1687855-6511-423a-bb75-27962b819e2b",
   "metadata": {},
   "source": [
    "Ans: It is more appropriate to use adjusted R-squared when comparing models with different numbers of independent variables or when adding independent variables to a model to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb63f3f1-402e-4fcb-896b-a8d501118d41",
   "metadata": {},
   "source": [
    "#### Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics calculated, and what do they represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc167d91-fd5f-4fc5-9792-b3fd2de40b0c",
   "metadata": {},
   "source": [
    "Ans: Root mean squared error (RMSE), mean squared error (MSE), and mean absolute error (MAE) are evaluation metrics used in regression analysis to measure the difference between the predicted and actual values of the dependent variable. \n",
    "- RMSE is the square root of the average of the squared differences between the predicted and actual values, \n",
    "- MSE is the average of the squared differences between the predicted and actual values, and \n",
    "- MAE is the average of the absolute differences between the predicted and actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850e4cc-8277-4481-9fae-c87965b7bd2f",
   "metadata": {},
   "source": [
    "#### Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7406e-954f-4bb2-9ede-f6a0ec9a0759",
   "metadata": {},
   "source": [
    "Ans: The advantage of using RMSE, MSE, and MAE as evaluation metrics is that they provide a quantitative measure of the error in the predictions of the model. The disadvantage is that they are sensitive to outliers and may not be appropriate for non-normal distributions. RMSE is also more heavily influenced by large errors than smaller ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f53df40-06db-4ba5-bd5e-661ca7717e12",
   "metadata": {},
   "source": [
    "#### Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is it more appropriate to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482b94d8-6f31-4a8a-940d-327e597ef9dc",
   "metadata": {},
   "source": [
    "Ans: Lasso regularization is a method of adding a penalty term to the cost function in linear regression to reduce the coefficients of the independent variables to zero, effectively performing feature selection. Lasso differs from Ridge regularization in that it uses the L1 norm of the coefficients as the penalty term, resulting in sparsity in the solution. Lasso is more appropriate to use when the data has a large number of features and only a few of them are expected to be important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd656b-2451-420f-83a2-19768bfd552e",
   "metadata": {},
   "source": [
    "#### Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an example to illustrate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf55abc-6876-4c24-a5b4-42dd3ad94a9c",
   "metadata": {},
   "source": [
    "Ans: Regularized linear models help prevent overfitting in machine learning by adding a penalty term to the loss function that shrinks the coefficients towards zero. This reduces the complexity of the model and prevents it from fitting the noise in the training data. For example, Ridge and Lasso regression are regularized linear models that help prevent overfitting by adding a penalty term to the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1997dc-b4ba-4c7d-a724-63951ee34d9e",
   "metadata": {},
   "source": [
    "#### Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best choice for regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea82e0e6-038d-4cc2-a590-becb4d8de625",
   "metadata": {},
   "source": [
    "Ans: The limitations of regularized linear models include the fact that they may not work well with highly correlated predictors, and they may not perform well when the relationship between the response and predictors is highly non-linear. Additionally, regularized linear models may not be the best choice when there is a large amount of noise in the data or when the number of predictors is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a95418-0c46-4dbb-95f7-5aab2c13a559",
   "metadata": {},
   "source": [
    "#### Q9. You are comparing the performance of two regression models using different evaluation metrics. Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better performer, and why? Are there any limitations to your choice of metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a3a89-afc7-4e5b-b599-2126f7ebe14f",
   "metadata": {},
   "source": [
    "Ans: It depends on the specific context and goals of the analysis. RMSE and MAE both measure different aspects of model performance, with RMSE being more sensitive to large errors and MAE being more robust to outliers. Therefore, the choice of metric should be based on the specific requirements and goals of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7bde7d-0ce3-4a51-8c90-ba400dea8ecd",
   "metadata": {},
   "source": [
    "#### Q10. You are comparing the performance of two regularized linear models using different types of regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the better performer, and why? Are there any trade-offs or limitations to your choice of regularization method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a7f8f7-b645-48d3-9687-cb1cc9e0d203",
   "metadata": {},
   "source": [
    "Ans: It depends on the specific context and goals of the analysis. Ridge and Lasso regularization both have different strengths and weaknesses, with Ridge being better for dealing with multicollinearity and Lasso being better for feature selection. Therefore, the choice of regularization method should be based on the specific requirements and goals of the analysis. There may also be trade-offs between the amount of regularization and model performance, and it may be necessary to tune the regularization parameter to find the optimal balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67284cd4-4159-4ae4-bf34-d7e212238131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
