{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7f2701-2f38-4eaa-8883-abd88c414138",
   "metadata": {},
   "source": [
    "#### Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8dc60-547b-427a-a2d5-427ce161df7f",
   "metadata": {},
   "source": [
    "Ans: **Lasso Regression** is a linear regression technique that adds an L1 regularization penalty term to the ordinary least squares regression. The L1 penalty shrinks the coefficient estimates towards zero and can result in sparse models where some of the coefficients are exactly equal to zero, effectively performing feature selection. \n",
    "\n",
    "Lasso Regression differs from other regression techniques such as Ridge Regression in the type of regularization used and the resulting coefficient estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490b529-60ae-4318-b96a-3346c4a63362",
   "metadata": {},
   "source": [
    "#### Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c315f6-5f14-4e78-9a67-3e0c44def168",
   "metadata": {},
   "source": [
    "Ans: The main advantage of using Lasso Regression in feature selection is that it can effectively identify and exclude irrelevant features from the model, resulting in a simpler and more interpretable model. \n",
    "\n",
    "The L1 regularization penalty in Lasso Regression encourages sparsity in the coefficient estimates, meaning that some of the coefficients can be exactly equal to zero, effectively removing the corresponding features from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a6691-732d-4130-900c-693d7e32a5fc",
   "metadata": {},
   "source": [
    "#### Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f732b8-66dd-4f37-a743-3dea4b9d1cb4",
   "metadata": {},
   "source": [
    "Ans: The interpretation of the coefficients in a Lasso Regression model is similar to that of ordinary least squares regression. The coefficients represent the change in the response variable associated with a one-unit increase in the predictor variable, while holding all other predictor variables constant.\n",
    "\n",
    "However, the coefficients in Lasso Regression are modified by the L1 penalty term, which can result in some coefficients being exactly equal to zero. The coefficients that are not equal to zero indicate the direction and strength of the relationship between the predictor variable and the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb63f3f1-402e-4fcb-896b-a8d501118d41",
   "metadata": {},
   "source": [
    "#### Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224018b7-a698-4ea8-9bc2-54c0cb9fc145",
   "metadata": {},
   "source": [
    "Ans: The main tuning parameter in Lasso Regression is the regularization parameter (lambda), which controls the strength of the L1 penalty term. Increasing lambda increases the level of regularization, resulting in more coefficients being set to zero, effectively performing stronger feature selection. \n",
    "\n",
    "The choice of the optimal lambda value can be made using cross-validation techniques to maximize the model's performance on a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850e4cc-8277-4481-9fae-c87965b7bd2f",
   "metadata": {},
   "source": [
    "#### Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80263e9-5f1b-4321-9a59-b73dc2689e57",
   "metadata": {},
   "source": [
    "Ans: Lasso Regression is a linear regression technique, and therefore it is not suitable for non-linear regression problems where the relationship between the predictor variables and the response variable is non-linear. \n",
    "\n",
    "Lasso Regression can be extended to non-linear regression problems by incorporating non-linear transformations of the predictor variables into the model, such as polynomial or interaction terms. \n",
    "\n",
    "This is known as polynomial Lasso Regression or interaction Lasso Regression, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f53df40-06db-4ba5-bd5e-661ca7717e12",
   "metadata": {},
   "source": [
    "#### Q6. What is the difference between Ridge Regression and Lasso Regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666ceef2-4e8f-4226-a84a-228e634d0016",
   "metadata": {},
   "source": [
    "Ans: The main difference between Ridge Regression and Lasso Regression is the type of regularization used. Ridge Regression uses an L2 regularization penalty, which shrinks the coefficient estimates towards zero but does not set any coefficients exactly equal to zero. \n",
    "\n",
    "Lasso Regression uses an L1 regularization penalty, which also shrinks the coefficient estimates towards zero but can result in sparse models where some coefficients are exactly equal to zero, effectively performing feature selection. \n",
    "\n",
    "Additionally, Ridge Regression is suitable for multicollinear data, while Lasso Regression is suitable for feature selection in situations where the number of predictors is large relative to the number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd656b-2451-420f-83a2-19768bfd552e",
   "metadata": {},
   "source": [
    "#### Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50101a14-1b1b-4cd0-9931-088dcf4bb22f",
   "metadata": {},
   "source": [
    "Ans: Yes, Lasso Regression can handle multicollinearity in the input features by penalizing the coefficients of the correlated features and shrinking them towards zero. \n",
    "\n",
    "This allows Lasso Regression to automatically perform feature selection by selecting only the most important features while setting the coefficients of the less important features to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1997dc-b4ba-4c7d-a724-63951ee34d9e",
   "metadata": {},
   "source": [
    "#### Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce9896e-8c34-49cc-9956-bb31287a9ec0",
   "metadata": {},
   "source": [
    "Ans: The optimal value of the regularization parameter (lambda) in Lasso Regression can be chosen through cross-validation. The dataset is split into training and validation sets, and the model is trained on the training set for different values of lambda. \n",
    "\n",
    "The model's performance is then evaluated on the validation set using a chosen evaluation metric. The lambda value that gives the best performance on the validation set is then chosen as the optimal lambda.\n",
    "\n",
    "Alternatively, the optimal value of lambda can be estimated using information criteria such as the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC). \n",
    "\n",
    "These criteria penalize the model's complexity and reward the goodness of fit, allowing for the selection of the most parsimonious model with the best fit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
