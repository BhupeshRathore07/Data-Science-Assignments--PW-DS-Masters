{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565c0957-ed5c-4055-90a8-904831d30b72",
   "metadata": {},
   "source": [
    "#### Q1. What is anomaly detection and what is its purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6def3f4-49d9-421e-be5c-e5e9e07cd0a3",
   "metadata": {},
   "source": [
    "Ans: `Anomaly detection` refers to the process of identifying rare or unusual patterns or observations within a dataset that deviate significantly from the norm. \n",
    "\n",
    "Its *purpose* is to detect and flag instances that are considered anomalous or potentially suspicious, which may indicate errors, fraud, or unusual behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13057386-c2b2-4d82-9736-b4a2461c42d6",
   "metadata": {},
   "source": [
    "#### Q2. What are the key challenges in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83b13f-df7f-49cc-802c-bcc8d83b0868",
   "metadata": {},
   "source": [
    "Ans: Key challenges in anomaly detection include defining what constitutes: \n",
    "- normal behavior, \n",
    "- handling imbalanced datasets where anomalies are rare, \n",
    "- selecting appropriate features for anomaly detection, \n",
    "- dealing with high-dimensional data, \n",
    "- determining an appropriate threshold for anomaly detection, and \n",
    "- adapting to evolving anomalies over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364eb54-ac37-4cb8-a3df-9edec2afcb6e",
   "metadata": {},
   "source": [
    "#### Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3129f97d-6b6a-4a22-a4ea-4f5022ccfae9",
   "metadata": {},
   "source": [
    "Ans: In **unsupervised anomaly detection**, labeled examples of anomalies are not provided during training. The algorithm learns the normal patterns and structures from the unlabeled data and identifies instances that deviate significantly from the learned norm as anomalies. Unsupervised methods do not require prior knowledge or labels, making them more flexible but potentially less accurate in identifying anomalies.\n",
    "\n",
    "On the other hand, **supervised anomaly detection** relies on labeled examples of anomalies during the training phase. The algorithm learns to distinguish between normal and anomalous instances based on the provided labels. Supervised methods can be more accurate in identifying anomalies since they have explicit knowledge of the anomalies they need to detect. However, they require a labeled training set, which may be difficult or expensive to obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63625f84-e106-448d-8608-04fe28746d5f",
   "metadata": {},
   "source": [
    "#### Q4. What are the main categories of anomaly detection algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ee651-2042-48af-b6c9-74abcb2ca5c3",
   "metadata": {},
   "source": [
    "Ans: The main categories of anomaly detection algorithms include:\n",
    "\n",
    "- **Statistical-based methods:** These methods use statistical techniques to model the normal behavior of the data and identify instances that significantly deviate from the expected statistical properties.\n",
    "\n",
    "- **Distance-based methods:** These algorithms compute distances or similarities between data points and consider instances that are far away from their neighbors in the feature space as anomalies.\n",
    "\n",
    "- **Density-based methods:** These methods identify anomalies based on the density of data points. Anomalies are typically areas of low-density compared to the surrounding data.\n",
    "\n",
    "- **Model-based methods:** These algorithms build models of the normal data distribution and classify instances as anomalies if they have a low probability under the learned model.\n",
    "\n",
    "- **Ensemble methods:** Ensemble approaches combine multiple anomaly detection algorithms or models to improve the accuracy and robustness of anomaly detection by leveraging the strengths of individual methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d662af46-ae3a-4636-aa79-ae5181a7e030",
   "metadata": {},
   "source": [
    "#### Q5. What are the main assumptions made by distance-based anomaly detection methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f35e1e-bd0d-4729-b14f-71a1bf7461d4",
   "metadata": {},
   "source": [
    "Ans: Distance-based anomaly detection methods make the following assumptions:\n",
    "\n",
    "- Anomalies are located far away from normal instances in the feature space.\n",
    "- Anomalies have dissimilarities or distances that significantly differ from the distances between normal instances.\n",
    "- Normal instances are more densely clustered in the feature space compared to anomalies.\n",
    "- The number of anomalies is relatively small compared to the number of normal instances.\n",
    "\n",
    "These assumptions guide the distance-based methods in identifying instances that are isolated or have large distances to their neighbors as anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2472a2ee-289c-431c-b53b-0092edc90f05",
   "metadata": {},
   "source": [
    "#### Q6. How does the LOF algorithm compute anomaly scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e18f7d-5e8b-42be-8605-63c4f416fbe6",
   "metadata": {},
   "source": [
    "Ans: The `LOF (Local Outlier Factor)` algorithm computes anomaly scores as follows:\n",
    "\n",
    "1. For each data point, LOF calculates the reachability distance to its k-nearest neighbors. The reachability distance represents how easily a point can be reached from its neighbors.\n",
    "\n",
    "2. The local reachability density (LRD) is computed for each point by taking the inverse of the average reachability distance of its k-nearest neighbors.\n",
    "\n",
    "3. LOF compares the LRD of a point with the LRDs of its neighbors. If the LRD of a point is significantly lower than the LRDs of its neighbors, it indicates that the point is in a sparser region and has a higher likelihood of being an anomaly.\n",
    "\n",
    "4. The anomaly score, which is the LOF score, is calculated as the average ratio of the LRD of a point to the LRDs of its neighbors. A higher LOF score signifies a higher probability of the point being an anomaly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578e651-f40c-46f2-b704-8f5665817405",
   "metadata": {},
   "source": [
    "#### Q7. What are the key parameters of the Isolation Forest algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21411b0-cfc8-49d4-b19b-0373481ac57b",
   "metadata": {},
   "source": [
    "Ans: The key parameters of the Isolation Forest algorithm are:\n",
    "\n",
    "1. **Number of trees:** This parameter specifies the number of isolation trees to be created. Increasing the number of trees can improve the accuracy of anomaly detection but may also increase computation time.\n",
    "\n",
    "2. **Subsampling size:** Isolation Forest randomly selects a subset of the data for constructing each tree. The subsampling size determines the size of the subsets. A smaller subsampling size can lead to more finely grained results, but it can also increase the chances of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8373255-4233-46a8-bee1-fcaca1cc1daa",
   "metadata": {},
   "source": [
    "#### Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c056e-a91c-4939-99c5-1902b1811ce1",
   "metadata": {},
   "source": [
    "Ans: In KNN with K=10, if a data point has only 2 neighbors of the same class within a radius of 0.5, its anomaly score would be relatively high. \n",
    "\n",
    "Since it has a small number of neighbors within the specified radius, it suggests that the point is isolated or dissimilar from the majority of the neighboring points. This isolation indicates a higher likelihood of the point being an anomaly.\n",
    "\n",
    "To calculate the anomaly score, we can consider the proportion of the data point's neighbors that belong to the same class within the specified radius. In this case, since all 2 neighbors are of the same class, the proportion is 2/2 = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fc2f9-2af5-4fe8-b58b-f827b4ee713a",
   "metadata": {},
   "source": [
    "#### Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a85cd3-6983-40c3-baf0-a4e881b9b511",
   "metadata": {},
   "source": [
    "Ans: In the Isolation Forest algorithm, the anomaly score for a data point is calculated based on its average path length (APL) compared to the average path length of the trees in the forest. \n",
    "\n",
    "Given:\n",
    "- Number of trees (T) = 100\n",
    "- Dataset size (N) = 3000\n",
    "- Data point's average path length (APL) = 5.0\n",
    "\n",
    "To calculate the anomaly score, we need to normalize the APL by comparing it to the expected average path length for normal data points in the isolation forest. The expected average path length for normal data points can be estimated using the formula:\n",
    "\n",
    "E(APL) = 2 * (log(N - 1) + 0.5772156649) - (2 * (N - 1) / N)\n",
    "\n",
    "Here, log represents the natural logarithm.\n",
    "\n",
    "Let's calculate the expected average path length for the given dataset size:\n",
    "\n",
    "E(APL) = 2 * (log(3000 - 1) + 0.5772156649) - (2 * (3000 - 1) / 3000)\n",
    "\n",
    "E(APL) ≈ 8.299\n",
    "\n",
    "Now, we can compute the anomaly score for the data point using the following formula:\n",
    "\n",
    "Anomaly Score = 2^(-APL / E(APL))\n",
    "\n",
    "Anomaly Score = 2^(-5.0 / 8.299)\n",
    "\n",
    "Anomaly Score ≈ 0.477\n",
    "\n",
    "Therefore, the anomaly score for the data point with an average path length of 5.0 compared to the average path length of the trees is approximately `0.477`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
