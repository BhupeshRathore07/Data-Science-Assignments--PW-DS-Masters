{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7f2701-2f38-4eaa-8883-abd88c414138",
   "metadata": {},
   "source": [
    "#### Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b176b4a5-172c-4fb8-8c75-2cf95526f9a5",
   "metadata": {},
   "source": [
    "Ans:\n",
    "- Missing values are absent data values in a dataset.\n",
    "- It's crucial to handle missing values as they can lead to biased or inaccurate model predictions. Ignoring missing values can also lead to incorrect conclusions, as it can skew the distribution of the remaining data.\n",
    "- Tree-based(decision trees and random forests) and distance-based (k-nearest neighbors (KNN) and Support Vector Machines (SVM)) methods are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490b529-60ae-4318-b96a-3346c4a63362",
   "metadata": {},
   "source": [
    "#### Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc32671f-a0cc-4556-80e5-35d7f9e8de83",
   "metadata": {},
   "source": [
    "Ans: \n",
    "1. Deletion\n",
    "2. Mean/median imputation\n",
    "3. Forward/Backward filling\n",
    "4. Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9ec52e-4fa8-40cb-b9fd-1088fa72792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A     B\n",
      "0  1.0   6.0\n",
      "1  2.0   NaN\n",
      "2  NaN   8.0\n",
      "3  4.0   NaN\n",
      "4  NaN  10.0\n",
      "5  6.0   NaN \n",
      "\n",
      "Deletion:\n",
      "      A    B\n",
      "0  1.0  6.0\n",
      "\n",
      "Mean/median imputation:\n",
      "       A     B\n",
      "0  1.00   6.0\n",
      "1  2.00   8.0\n",
      "2  3.25   8.0\n",
      "3  4.00   8.0\n",
      "4  3.25  10.0\n",
      "5  6.00   8.0\n",
      "\n",
      "Forward/Backward filling:\n",
      "      A     B\n",
      "0  1.0   6.0\n",
      "1  2.0   6.0\n",
      "2  2.0   8.0\n",
      "3  4.0   8.0\n",
      "4  4.0  10.0\n",
      "5  6.0  10.0\n",
      "\n",
      "Interpolation:\n",
      "      A     B\n",
      "0  1.0   6.0\n",
      "1  2.0   7.0\n",
      "2  3.0   8.0\n",
      "3  4.0   9.0\n",
      "4  5.0  10.0\n",
      "5  6.0  10.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Deletion\n",
    "df = pd.DataFrame({'A': [1, 2, None, 4, None, 6],\n",
    "                   'B': [6, None, 8, None, 10, None]})\n",
    "print(df, '\\n')\n",
    "print(\"Deletion:\\n\", df.dropna())\n",
    "\n",
    "\n",
    "# Mean/median imputation\n",
    "df = pd.DataFrame({'A': [1, 2, None, 4, None, 6],\n",
    "                   'B': [6, None, 8, None, 10, None]})\n",
    "print(\"\\nMean/median imputation:\\n\", df.fillna(df.mean()))\n",
    "\n",
    "\n",
    "# Forward/Backward filling\n",
    "df = pd.DataFrame({'A': [1, 2, None, 4, None, 6],\n",
    "                   'B': [6, None, 8, None, 10, None]})\n",
    "print(\"\\nForward/Backward filling:\\n\", df.fillna(method='ffill').fillna(method='bfill'))\n",
    "\n",
    "\n",
    "# Interpolation\n",
    "df = pd.DataFrame({'A': [1, 2, None, 4, None, 6],\n",
    "                   'B': [6, None, 8, None, 10, None]})\n",
    "print(\"\\nInterpolation:\\n\", df.interpolate(method='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a6691-732d-4130-900c-693d7e32a5fc",
   "metadata": {},
   "source": [
    "#### Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff837e4-5ec8-4b84-8f4a-aba0ebd84c9a",
   "metadata": {},
   "source": [
    "Ans: **Imbalanced data** refers to a situation where the classes in a classification problem are not represented equally. \n",
    "\n",
    "If imbalanced data is not handled, the machine learning model will be biased towards the majority class, resulting in poor predictions for the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb63f3f1-402e-4fcb-896b-a8d501118d41",
   "metadata": {},
   "source": [
    "#### Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee34c6c-448f-4620-b6d0-108d126c47bd",
   "metadata": {},
   "source": [
    "Ans: Up-sampling and down-sampling are techniques used to address imbalanced data.\n",
    "\n",
    "Up-sampling involves increasing the number of instances in the minority class, while down-sampling involves decreasing the number of instances in the majority class.\n",
    "\n",
    "Eg: In a binary classification problem with 100 instances, if the positive class has only 10 instances, up-sampling can be used to create new instances of the positive class to make the class distribution more balanced. On the other hand, down-sampling can be used if the negative class has a very large number of instances compared to the positive class.\n",
    "\n",
    "Up-sampling and down-sampling are required when dealing with imbalanced data to ensure that the machine learning model is not biased towards the majority class and can accurately predict both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850e4cc-8277-4481-9fae-c87965b7bd2f",
   "metadata": {},
   "source": [
    "#### Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23bc13-a690-4fbd-b85c-0fa289410ca8",
   "metadata": {},
   "source": [
    "Ans: **Data augmentation** is a technique used to artificially increase the size of a dataset by generating new data points from the existing ones. It is commonly used in machine learning to address the problem of limited data.\n",
    "\n",
    "**SMOTE (Synthetic Minority Over-sampling Technique)** is a data augmentation technique used to address the problem of imbalanced data. It works by creating synthetic examples of the minority class by interpolating between existing examples. SMOTE is particularly useful when the number of instances in the minority class is very small compared to the majority class. By creating synthetic examples, SMOTE can help balance the class distribution and prevent the machine learning model from being biased towards the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f53df40-06db-4ba5-bd5e-661ca7717e12",
   "metadata": {},
   "source": [
    "#### Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c6c9b0-a44a-4c10-a8b5-33d51a3c643d",
   "metadata": {},
   "source": [
    "Ans: **Outliers** are data points in a dataset that are significantly different from other data points. They can be caused by errors in data collection or measurement, or they may represent valid but rare instances.\n",
    "\n",
    "It is essential to handle outliers because they can have a significant impact on the results of machine learning algorithms. Outliers can skew statistical measures such as the mean and standard deviation, which can in turn affect the performance of machine learning models that rely on these measures. Outliers can also create noise in the data, which can lead to overfitting or poor generalization of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd656b-2451-420f-83a2-19768bfd552e",
   "metadata": {},
   "source": [
    "#### Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37950c96-4994-4372-9328-76a32af30029",
   "metadata": {},
   "source": [
    "Ans: Some techniques that can be used to handle missing data in an analysis:\n",
    "\n",
    "1. Deletion: This involves removing the entire row or column that contains the missing value. This can be done if the missing data is relatively small compared to the total dataset.\n",
    "\n",
    "2. Imputation: This involves estimating the missing value based on the other available data. Mean, median, mode, regression, and k-nearest neighbor imputation are some common imputation techniques.\n",
    "\n",
    "3. Prediction: This involves using a machine learning model to predict the missing values. This technique can be effective if there is enough data available to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1997dc-b4ba-4c7d-a724-63951ee34d9e",
   "metadata": {},
   "source": [
    "#### Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a847a689-61c3-4bc0-ab4a-8f3d96c417f0",
   "metadata": {},
   "source": [
    "Ans: Several strategies that can be used:\n",
    "\n",
    "1. Visual inspection: This involves creating plots or charts of the data to visually identify any patterns or trends in the missing data.\n",
    "\n",
    "2. Statistical tests: This involves conducting statistical tests to determine if there is a significant difference between the missing and non-missing data. For example, a t-test or chi-squared test can be used to determine if the missing data is related to a specific variable.\n",
    "\n",
    "3. Machine learning techniques: This involves using machine learning models to predict the missing values and then comparing the predicted values to the actual values. If the model performs well, it suggests that the missing data is missing at random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a95418-0c46-4dbb-95f7-5aab2c13a559",
   "metadata": {},
   "source": [
    "#### Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd5f92-6eb0-4f4f-a091-c74ca04b1741",
   "metadata": {},
   "source": [
    "Ans: The several strategies that can be used to evaluate the performance of a machine learning model on an imbalanced dataset:\n",
    "\n",
    "1. Resampling techniques: This involves oversampling the minority class or undersampling the majority class to balance the dataset. This can improve the performance of the model on the minority class, but may also introduce bias.\n",
    "\n",
    "2. Cost-sensitive learning: This involves assigning different misclassification costs to the different classes to reflect the imbalance in the dataset. This can improve the performance of the model on the minority class.\n",
    "\n",
    "3. Evaluation metrics: This involves using evaluation metrics that are specifically designed for imbalanced datasets, such as Area Under the ROC Curve (AUC-ROC), Area Under the Precision-Recall Curve (AUC-PR), and balanced accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa59539f-93f5-4f76-8209-ff5d86b22025",
   "metadata": {},
   "source": [
    "#### Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb866ca-8dde-424b-86d0-a2e956ba7089",
   "metadata": {},
   "source": [
    "Ans: To balance an unbalanced dataset with a majority class, several methods to down-sample the majority class such as:\n",
    "\n",
    "1. Random undersampling: randomly selecting a subset of the majority class to match the size of the minority class.\n",
    "\n",
    "2. Cluster-based undersampling: identifying clusters in the majority class and selecting representative samples from each cluster.\n",
    "\n",
    "3. Tomek Links: removing the samples of the majority class that are close to the minority class.\n",
    "\n",
    "4. NearMiss: selecting samples from the majority class that are closest to the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b08a3e-4aab-4d1d-9767-4a2304a702b6",
   "metadata": {},
   "source": [
    "#### Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a32ad-609f-4426-8bd9-ddd3c9ed20db",
   "metadata": {},
   "source": [
    "Ans: To balance an unbalanced dataset with a minority class, several methods to up-sample the minority class such as:\n",
    "\n",
    "1. Random oversampling: randomly duplicating samples from the minority class to match the size of the majority class.\n",
    "\n",
    "2. Synthetic Minority Over-sampling Technique (SMOTE): generating synthetic samples for the minority class based on the nearest neighbors in feature space.\n",
    "\n",
    "3. Adaptive Synthetic (ADASYN): generating synthetic samples for the minority class based on the density of the samples.\n",
    "\n",
    "4. Oversampling with Cluster Centroids: creating clusters from the majority class and replacing each cluster with the centroid of the cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
